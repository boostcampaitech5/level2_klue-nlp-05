# PATH
TRAIN_PATH: "/opt/ml/dataset/train/train.csv"
DEV_PATH: "/opt/ml/dataset/train/train.csv"
SPLIT_TRAIN_PATH: "/opt/ml/dataset/save_split_dataset/train.csv"
SPLIT_DEV_PATH: "/opt/ml/dataset/save_split_dataset/dev.csv"

OUTPUT_DIR: "./results"
LOGGING_DIR: "./logs"
MODEL_SAVE_DIR: "./best_model"

# MODEL (확인 필수)
MODEL_NAME: "klue/roberta-large"
TOTAL_SAVE_MODEL: 5

# HYPER PARAMETER (확인 필수)
MAX_EPOCH: 3
LR: 2.0e-5 # Example Format : 5.0e-5 / 5.e-5 / 5.E-5
BATCH_SIZE: 32
WARMUP_STEP: 400
RATIO: 0.15 # Train Validation Split ratio
WEIGHT_DECAY: 0.1

# LOG
SAVING_STEP: 500
LOGGING_STEP: 500
EVAL_STEP: 500

# WANDB (확인 필수)
WANDB_PROJECT: "hanja_test"
WANDB_NAME: "hanja_special_large"

# WANDB SWEEP (확인 필수 및 양식 확인(들여쓰기))
SWEEP_AVAILABLE: 0 # SWEEP을 사용할 것인지 (1 : 사용, 0 : 미사용)
SWEEP_COUNT: 3 # SWEEP 실행 횟수
SWEEP_CONFIGURATION: # SWEEP 세부 내용 설정
  method: 'random'
  name: 'sweep_name'
  metric:
    goal: 'minimize'
    name: 'eval/loss'
  parameters:
    batch_size:
      values:
      - 8
      - 32
    epochs:
      values:
      - 5
      - 20
    lr:
      max: 1.0e-4
      min: 1.0e-6

# Custom Model (확인 필수)
MODEL_TYPE: 'entity_special' # 'base', 'entity_special', 'entity_punct'